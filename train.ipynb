{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_folder_images(folder_name):\n",
    "\n",
    "    # specify the folder path\n",
    "    folder_path = f\"alphabet_data/{folder_name}\"\n",
    "\n",
    "    # initialize an empty list to store the image arrays\n",
    "    image_arrays = []\n",
    "\n",
    "    # loop through each file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # check that the file is an image file (e.g. JPEG, PNG)\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # construct the full file path\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # read the image file as a numpy array\n",
    "            img_array = cv2.imread(file_path)\n",
    "\n",
    "            #gray the images\n",
    "            # img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY) # from 3 channels to 1 channel\n",
    "            # # coverting to gray scale gets rid of one dimension, so we add it back in, this time with 1 channel\n",
    "            # # Add an extra dimension to the grayscale image\n",
    "            # img_array = np.expand_dims(img_array, axis=-1)\n",
    "\n",
    "            # add the image array to the list\n",
    "            image_arrays.append(img_array)\n",
    "\n",
    "    # convert the list of image arrays to a numpy array\n",
    "    image_arrays = np.array(image_arrays)\n",
    "    return image_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_images_and_labels():\n",
    "    a = convert_folder_images(\"a\")\n",
    "    # make labels for all photos based on how many images are in the folder\n",
    "    # the folder names gives you the label for each folder of images\n",
    "\n",
    "    b = convert_folder_images(\"b\")\n",
    "    c = convert_folder_images(\"c\")\n",
    "    d = convert_folder_images(\"d\")\n",
    "    e = convert_folder_images(\"e\")\n",
    "\n",
    "    labels_a = np.full(len(a),\"a\")\n",
    "    labels_b = np.full(len(b),\"b\")\n",
    "    labels_c = np.full(len(c),\"c\")\n",
    "    labels_d = np.full(len(d),\"d\")\n",
    "    labels_e = np.full(len(e),\"e\")\n",
    "    # print(labels_e.shape)\n",
    "    images = np.vstack((a,b,c,d,e))/255 # divide by 255 for normalization\n",
    "    # labels = np.append(labels_a, (labels_b, labels_c, labels_d, labels_e))\n",
    "\n",
    "    # Convert string labels to numerical labels using LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    # concatenate all the labels together\n",
    "    labels = np.concatenate(\n",
    "        (labels_a, labels_b, labels_c, labels_d, labels_e), axis=0)\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "\n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make training, validation, and testing sets\n",
    "images,labels = get_all_images_and_labels()\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=2)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=2)\n",
    "# images[5][:][:][:].shape\n",
    "# plt.imshow(one_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(224, 224,3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "# type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# configure the learning process\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              # use sparse cross entropy since your data is integer encoded, NOT hot-encoded (0s and 1s)\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']),\n",
    "# print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found, using CPU instead\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and set device accordingly\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "else:\n",
    "    print(\"No GPU found, using CPU instead\")\n",
    "    device_name = '/cpu:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure the learning process\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              # use sparse cross entropy since your data is integer encoded, NOT hot-encoded (0s and 1s)\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']),\n",
    "# print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def fit_model():\n",
    "    model.fit(x_train,\n",
    "              y_train,\n",
    "              batch_size=50,\n",
    "              epochs=10,\n",
    "              validation_data=(x_valid, y_valid), verbose=1,\n",
    "              callbacks=None)\n",
    "# test the accuracy of model with testing ste\n",
    "def test_set_eval():\n",
    "\n",
    "    # Evaluate the model on test set\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    # Print test accuracy\n",
    "    print('\\n', 'Test accuracy:', score[1])\n",
    "    # model.predict(x_test)\n",
    "# export the model to the \"Model\" folder\n",
    "def export_model():\n",
    "    want_to_export = input(\"export model? ('true' or 'false'\")\n",
    "    if want_to_export:\n",
    "        model_path = 'Model/keras_model.h5'\n",
    "        tf.keras.models.save_model(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E8DEB1F948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E8DEB1F948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E8DEB1F948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.7236 - accuracy: 0.3313WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001E8DD313708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001E8DD313708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001E8DD313708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4/4 [==============================] - 6s 1s/step - loss: 5.7236 - accuracy: 0.3313 - val_loss: 1.9320 - val_accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 3.5114 - accuracy: 0.6000 - val_loss: 0.2435 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5622 - accuracy: 0.8438 - val_loss: 0.3080 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.1047 - accuracy: 0.9688 - val_loss: 0.2318 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 4.1576e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "\n",
      " Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create a TensorFlow session and set it to use the specified device\n",
    "with tf.device(device_name):\n",
    "    # train the model\n",
    "    fit_model()\n",
    "    test_set_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_set_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
